{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# KNOWN ISSUES OF THIS SCRIPT:\n",
        "# The script currently only produces job title, post date, number of application, and job description\n",
        "\n",
        "# ADVANTAGES OF THIS SCRIPT:\n",
        "# has the ability to scrape LinkedIn using its own api without the risk of being blocked or banned\n",
        "\n",
        "import time\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Customize the scrape with job title and job location\n",
        "title = \"Data Intern\"\n",
        "location = \"United States\"\n",
        "job_list = []\n",
        "start_time = time.time()  # Record the start time\n",
        "runtime_limit = 120  # Force scraping to run for at least 60 seconds\n",
        "\n",
        "# Customize the starting point of the webpage, eg. start scraping at 0 until page 500 with an increment of 25 pages each time\n",
        "# technically, the larger the range, the more output it will produce, however the results can vary from time to time\n",
        "while time.time() - start_time < runtime_limit:\n",
        "  for start in range(0, 1500, 25):\n",
        "    list_url = f\"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={title}&location={location}&start={start}\"\n",
        "    response = requests.get(list_url)\n",
        "    #if response.status_code != 200:\n",
        "        #print(f\"Failed to retrieve jobs for start={start}, status={response.status_code}\")\n",
        "        #continue\n",
        "\n",
        "    list_data = response.text\n",
        "    list_soup = BeautifulSoup(list_data, \"html.parser\")\n",
        "    page_jobs = list_soup.find_all(\"li\")\n",
        "\n",
        "    id_list = []\n",
        "    for job in page_jobs:\n",
        "        base_card_div = job.find(\"div\", {\"class\": \"base-card\"})\n",
        "        if base_card_div:\n",
        "            job_id = base_card_div.get(\"data-entity-urn\").split(\":\")[3]\n",
        "            id_list.append(job_id)\n",
        "\n",
        "    for job_id in id_list:\n",
        "        job_url = f\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}\"\n",
        "        job_response = requests.get(job_url)\n",
        "        #if job_response.status_code != 200:\n",
        "            #print(f\"Failed to retrieve job details for job_id={job_id}, status={job_response.status_code}\")\n",
        "            #continue\n",
        "\n",
        "        job_soup = BeautifulSoup(job_response.text, \"html.parser\")\n",
        "        job_post = {}\n",
        "\n",
        "        try:\n",
        "            job_post[\"job_title\"] = job_soup.find(\"h2\", {\"class\": \"top-card-layout__title\"}).text.strip()\n",
        "        except:\n",
        "            job_post[\"job_title\"] = None\n",
        "\n",
        "        try:\n",
        "            job_post[\"company_name\"] = job_soup.find(\"a\", {\"class\": \"topcard__org-name-link\"}).text.strip()\n",
        "        except:\n",
        "            job_post[\"company_name\"] = None\n",
        "\n",
        "        try:\n",
        "          job_post[\"location\"] = job_soup.find(\"span\", {\"class\": \"topcard__flavor topcard__flavor--bullet\"}).text.strip()\n",
        "        except:\n",
        "          job_post[\"location\"] = None\n",
        "\n",
        "        try:\n",
        "            job_post[\"time_posted\"] = job_soup.find(\"span\", {\"class\": \"posted-time-ago__text\"}).text.strip()\n",
        "        except:\n",
        "            job_post[\"time_posted\"] = None\n",
        "\n",
        "        try:\n",
        "            job_post[\"num_applicants\"] = job_soup.find(\"span\", {\"class\": \"num-applicants__caption\"}).text.strip()\n",
        "        except:\n",
        "            job_post[\"num_applicants\"] = None\n",
        "        # try:\n",
        "        #     job_post[\"Seniority Level\"] = job_soup.find(\"span\", {\"class\": \"description__job-criteria-text description__job-criteria-text--criteria\"}).text.strip()\n",
        "        # except:\n",
        "        #     job_post[\"Seniority Level\"] = None\n",
        "\n",
        "        # try:\n",
        "        #     job_post[\"Employment Type\"] = job_soup.find(\"span\", {\"class\": \"description__job-criteria-text description__job-criteria-text--criteria\"}).text.strip()\n",
        "        # except:\n",
        "        #     job_post[\"Employment Type\"] = None\n",
        "\n",
        "        # try:\n",
        "        #     job_post[\"Job Function\"] = job_soup.find(\"span\", {\"class\": \"description__job-criteria-text description__job-criteria-text--criteria\"}).text.strip()\n",
        "        # except:\n",
        "        #     job_post[\"Job Function\"] = None\n",
        "        # Dynamically extract criteria like Seniority Level, Employment Type, etc.\n",
        "        criteria_items = job_soup.find_all(\"li\", class_=\"description__job-criteria-item\")\n",
        "\n",
        "        for item in criteria_items:\n",
        "            try:\n",
        "                header = item.find(\"h3\", class_=\"description__job-criteria-subheader\").text.strip()\n",
        "                value = item.find(\"span\", class_=\"description__job-criteria-text description__job-criteria-text--criteria\").text.strip()\n",
        "\n",
        "                if \"Seniority\" in header:\n",
        "                    job_post[\"Seniority Level\"] = value\n",
        "                elif \"Employment\" in header:\n",
        "                    job_post[\"Employment Type\"] = value\n",
        "                elif \"Job function\" in header:\n",
        "                    job_post[\"Job Function\"] = value\n",
        "                elif \"Industries\" in header:\n",
        "                    job_post[\"Industries\"] = value\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "\n",
        "        try:\n",
        "            job_post[\"job_description\"] = job_soup.find(\"div\", {\"class\": \"decorated-job-posting__details\"}).text.strip()\n",
        "        except:\n",
        "            job_post[\"job_description\"] = None\n",
        "\n",
        "        job_list.append(job_post)\n",
        "\n",
        "df = pd.DataFrame(job_list)\n",
        "df = df.dropna(subset=['job_title']) if df['job_title'].isnull().any() else df\n",
        "df.to_csv('Data_Science_Internship_Full.csv', index = False)\n"
      ],
      "metadata": {
        "id": "6bQ26WrYxOCL"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}